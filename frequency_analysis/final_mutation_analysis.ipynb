{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4b054b77",
   "metadata": {},
   "source": [
    "# Frequency Analysis\n",
    "This notebook consolidates loading, annotation, filtering, and visualization of mutation data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6329910",
   "metadata": {},
   "source": [
    "## Section 1: Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a45978a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Imports & Dependencies\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import os\n",
    "import glob\n",
    "from pathlib import Path\n",
    "from Bio import SeqIO, Seq\n",
    "from fpdf import FPDF\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "from tqdm import tqdm\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44772085",
   "metadata": {},
   "source": [
    "## Section 2: Configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b323db9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Paths\n",
    "metadata_path           = Path(\".../.../.../chronic_metadata.csv\")\n",
    "base_dir                = Path(\".../.../.../mutation_analysis\")\n",
    "problematic_path        = Path(\".../.../.../Recurrent_mutations.tsv\")\n",
    "manual_changes_path     = Path(\".../.../.../mutation_manual.csv\")\n",
    "suspicious_mutations_path = Path(\".../.../.../suspected_muts_with_soft_filtering_trim_40.csv\")\n",
    "patients_tp_path        = Path(\".../.../.../patients_timepoints_to_analyze.csv\")\n",
    "consenss_fasta_path     = Path(\".../.../.../wuhan_ref.fasta\")\n",
    "plot_folder             = Path(\".../.../.../Frequency_Graphs\")\n",
    "freqs_folder            = Path(\".../.../.../Frequency_Tables\")\n",
    "\n",
    "# 3. ORF Coordinates & Protein Map\n",
    "ORF_COORDS = {\n",
    "    'ORF1a': (266, 13467), 'ORF1b': (13468, 21556), 'S': (21563, 25384),\n",
    "    'ORF3a': (25393, 26220), 'E': (26245, 26472),  'M': (26523, 27191),\n",
    "    'ORF6': (27202, 27387), 'ORF7a': (27394, 27759), 'ORF7b': (27756, 27887),\n",
    "    'ORF8': (27894, 28259),  'N': (28274, 29533),  'ORF10': (29558, 29674)\n",
    "}\n",
    "protein_abbreviations = {\n",
    "    'envelope protein': 'E', 'membrane glycoprotein': 'M',\n",
    "    'nucleocapsid phosphoprotein': 'N', 'ORF10 protein': 'ORF10',\n",
    "    'orf1ab polyprotein': 'ORF1ab', 'ORF3a protein': 'ORF3a',\n",
    "    'ORF6 protein': 'ORF6', 'ORF7a protein': 'ORF7a',\n",
    "    'ORF8 protein': 'ORF8', 'surface glycoprotein': 'S'\n",
    "}\n",
    "\n",
    "# 4. Timepoint Adjustments & Patient Groups\n",
    "days_to_add = {\"N1\":18,\"N2\":29,\"N3\":60,\"N4\":0,\"N7\":41,\"N8\":4,\"P3\":30,\"P4\":26,\"P5\":5}\n",
    "\n",
    "# 5. Plot Colors & Styles\n",
    "PREDEFINED_COLORS = [\n",
    "    \"#E69F00\",\"#56B4E9\",\"#009E73\",\"#F0E442\",\"#0072B2\",\n",
    "    \"#D55E00\",\"#CC79A7\",\"#000000\",\"#CC6677\",\"#882255\",\n",
    "    \"#44AA99\",\"#117733\",\"#332288\",\"#AA4499\",\"#88CCEE\"\n",
    "]\n",
    "FONT_SIZE_MAIN       = 45\n",
    "FONT_SIZE_AXIS_TITLE = 40\n",
    "FONT_SIZE_TICK       = 30\n",
    "FONT_SIZE_LEGEND     = 30\n",
    "MARKER_SIZE          = 10\n",
    "LINE_WIDTH           = 4\n",
    "OPACITY              = 0.5\n",
    "LOW_FREQ_COLOR       = \"#A9A9A9\"\n",
    "PLOT_HEIGHT          = 900\n",
    "PLOT_WIDTH           = 1200\n",
    "GRID_COLOR           = 'lightgrey'\n",
    "TEXT_COLOR           = 'black'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1cd9050",
   "metadata": {},
   "source": [
    "## Section 4: Load & Merge Mutation Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3af43e19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. Load and Merge\n",
    "all_merged_files = glob.glob(str(base_dir / \"*/*/*merged.csv\"))\n",
    "df_list = []\n",
    "for file_path in all_merged_files:\n",
    "    parts   = Path(file_path).parts\n",
    "    patient = parts[-3]\n",
    "    tp      = int(parts[-2])\n",
    "    df      = pd.read_csv(file_path)\n",
    "    df.insert(0, \"patient\",     patient)\n",
    "    df.insert(1, \"timepoint\",   tp)\n",
    "    df_list.append(df)\n",
    "\n",
    "combined_mutations_df = pd.concat(df_list, ignore_index=True) if df_list else pd.DataFrame()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3999fb51",
   "metadata": {},
   "source": [
    "## Section 5: Apply Manual Corrections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8606ac0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7. Apply Manual Changes\n",
    "manual_df = pd.read_csv(manual_changes_path).rename(columns={'patient_id':'patient'})\n",
    "combined_mutations_df['manually_changed'] = combined_mutations_df.get('manually_changed', False)\n",
    "\n",
    "for _, row in manual_df.iterrows():\n",
    "    mask = (\n",
    "        (combined_mutations_df['patient']   == row['patient']) &\n",
    "        (combined_mutations_df['timepoint']== row['timepoint']) &\n",
    "        (combined_mutations_df['mutation']  == row['mutation'])\n",
    "    )\n",
    "    fixed = row.get('fixed_freq')\n",
    "    if pd.notna(fixed):\n",
    "        if mask.any():\n",
    "            combined_mutations_df.loc[mask, ['final_freq','manually_changed']] = [fixed, True]\n",
    "        else:\n",
    "            new = {**{c:None for c in combined_mutations_df.columns}}\n",
    "            new.update(patient=row['patient'],\n",
    "                       timepoint=row['timepoint'],\n",
    "                       mutation=row['mutation'],\n",
    "                       final_freq=fixed,\n",
    "                       manually_changed=True)\n",
    "            combined_mutations_df = pd.concat(\n",
    "                [combined_mutations_df, pd.DataFrame([new])],\n",
    "                ignore_index=True\n",
    "            )\n",
    "\n",
    "# Drop one known artefact\n",
    "combined_mutations_df = combined_mutations_df[\n",
    "    combined_mutations_df['mutation'] != 'T22204+GAGCCAGAA'\n",
    "]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e03a5a2",
   "metadata": {},
   "source": [
    "## Section 6: Filter Relevant Patients & Timepoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45fc5323",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8. Load whitelist and filter\n",
    "patients_tp_df = pd.read_csv(patients_tp_path)\n",
    "patients_tp_df['timepoints'] = (\n",
    "    patients_tp_df['timepoints']\n",
    "    .astype(str)\n",
    "    .str.strip('[]')\n",
    "    .str.split(',')\n",
    "    .apply(lambda L: [int(x) for x in L if x.strip().isdigit()])\n",
    ")\n",
    "pt_dict = dict(zip(patients_tp_df['patient'], patients_tp_df['timepoints']))\n",
    "\n",
    "def is_relevant(r):\n",
    "    return r['patient'] in pt_dict and r['timepoint'] in pt_dict[r['patient']]\n",
    "\n",
    "filtered_mutations_df = combined_mutations_df.loc[\n",
    "    combined_mutations_df.apply(is_relevant, axis=1)\n",
    "].copy()\n",
    "\n",
    "# Remove mutations never >0 in any timepoint\n",
    "present = (\n",
    "    filtered_mutations_df\n",
    "    .query(\"final_freq > 0\")\n",
    "    .groupby('patient')['mutation']\n",
    "    .unique()\n",
    "    .explode()\n",
    "    .reset_index()\n",
    ")\n",
    "filtered_mutations_df = filtered_mutations_df.merge(\n",
    "    present, on=['patient','mutation'], how='inner'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a9dad83",
   "metadata": {},
   "source": [
    "## Section 7: Load Reference & Define Annotation Functions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b34efba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_wuhan_ref(path_to_fasta):\n",
    "    record = SeqIO.read(path_to_fasta, \"fasta\")\n",
    "    return str(record.seq).upper()\n",
    "\n",
    "# --- Deletion annotation usinע custom logic ---\n",
    "def process_deletion(mutation: str, consensus_sequence: str, protein_dict: dict) -> str:\n",
    "    if \"-\" not in mutation:\n",
    "        return mutation\n",
    "    \n",
    "    deletion_part = mutation.split(\"-\")[1]\n",
    "    num_deleted_nucleotides = len(deletion_part)\n",
    "    if num_deleted_nucleotides % 3 != 0:\n",
    "        return mutation\n",
    "\n",
    "    match = re.search(r'\\d+', mutation)\n",
    "    if not match:\n",
    "        return mutation\n",
    "    start_pos = int(match.group())\n",
    "    protein = None\n",
    "    for prot, (start, end) in protein_dict.items():\n",
    "        if start <= start_pos <= end:\n",
    "            protein = prot\n",
    "            break\n",
    "    if not protein:\n",
    "        return mutation\n",
    "\n",
    "    deleted_amino_acids = num_deleted_nucleotides // 3\n",
    "    aa_start_pos = (start_pos - protein_dict[protein][0]) // 3 + 2\n",
    "    if deleted_amino_acids == 1:\n",
    "        aa_range = f\"{aa_start_pos}\"\n",
    "    else:\n",
    "        aa_range = f\"{aa_start_pos}-{aa_start_pos + deleted_amino_acids}\"\n",
    "\n",
    "    return f\"{protein}:Δ{aa_range}\"\n",
    "\n",
    "# --- Core mutation annotation logic ---\n",
    "def annotate_mutation(mutation, ref_seq, protein_dict):\n",
    "    match_sub = re.match(r'^([ACGT])(\\d+)([ACGT])$', mutation)\n",
    "    match_ins = re.match(r'^([ACGT])(\\d+)\\+([ACGT]+)$', mutation)\n",
    "    match_del = re.match(r'^([ACGT])(\\d+)-([ACGT]*)$', mutation)\n",
    "\n",
    "    def is_valid_position(pos):\n",
    "        return pos is not None and 1 <= pos <= len(ref_seq)\n",
    "\n",
    "    if match_sub:\n",
    "        ref, pos_str, alt = match_sub.groups()\n",
    "        pos = int(pos_str)\n",
    "        if not is_valid_position(pos):\n",
    "            return None, mutation, 'out_of_bounds'\n",
    "        if ref_seq[pos - 1].upper() != ref:\n",
    "            return None, mutation, 'mismatch'\n",
    "        for orf, (start, end) in protein_dict.items():\n",
    "            if start <= pos <= end:\n",
    "                rel_pos = pos - start\n",
    "                codon_start = start + (rel_pos // 3) * 3\n",
    "                codon_seq = ref_seq[codon_start - 1: codon_start + 2]\n",
    "                if len(codon_seq) != 3:\n",
    "                    return orf, mutation, 'syn'\n",
    "                codon_list = list(codon_seq)\n",
    "                codon_pos = pos - codon_start\n",
    "                if codon_pos < 0 or codon_pos > 2:\n",
    "                    return orf, mutation, 'syn'\n",
    "                codon_list[codon_pos] = alt\n",
    "                aa_orig = Seq.Seq(codon_seq).translate()\n",
    "                aa_new = Seq.Seq(''.join(codon_list)).translate()\n",
    "                if aa_orig == aa_new:\n",
    "                    return orf, mutation, 'syn'\n",
    "                else:\n",
    "                    aa_pos = (rel_pos // 3) + 1\n",
    "                    return orf, f\"{aa_orig}{aa_pos}{aa_new}\", 'non-syn'\n",
    "        return None, mutation, 'syn'\n",
    "\n",
    "    elif match_ins:\n",
    "        ref, pos_str, ins_seq = match_ins.groups()\n",
    "        pos = int(pos_str)\n",
    "        if not is_valid_position(pos):\n",
    "            return None, mutation, 'out_of_bounds'\n",
    "        for orf, (start, end) in protein_dict.items():\n",
    "            if start <= pos <= end:\n",
    "                return orf, mutation, 'indel'\n",
    "        return None, mutation, 'indel'\n",
    "\n",
    "    elif match_del:\n",
    "        ref, pos_str, del_seq = match_del.groups()\n",
    "        pos = int(pos_str)\n",
    "        if not is_valid_position(pos):\n",
    "            return None, mutation, 'out_of_bounds'\n",
    "        formatted = process_deletion(mutation, ref_seq, protein_dict)\n",
    "        if \":\" in formatted:\n",
    "            return formatted.split(\":\")[0], formatted, 'indel'\n",
    "        else:\n",
    "            return None, formatted, 'indel'\n",
    "\n",
    "    return None, mutation, 'unknown'\n",
    "\n",
    "def annotate_dataframe(df, ref_seq, protein_dict):\n",
    "    # Filter out mutations that start or end with 'N'\n",
    "    n_df = df[df['mutation'].str.startswith('N') & df['mutation'].str.endswith('N')].copy()\n",
    "    df = df[~df['mutation'].str.startswith('N') & ~df['mutation'].str.endswith('N')].copy()\n",
    "\n",
    "    def apply_annotation(row):\n",
    "        orf, mut_aa, mut_type = annotate_mutation(row['mutation'], ref_seq, protein_dict)\n",
    "\n",
    "        # Fallback to protein_y if ORF is missing\n",
    "        if orf is None and pd.notna(row.get('protein_y')):\n",
    "            orf = row['protein_y']\n",
    "\n",
    "        # Build final manual_mut_AA\n",
    "        if mut_type == 'non-syn' and orf is not None:\n",
    "            manual_mut_AA = f\"{orf}:{mut_aa}\"\n",
    "        else:\n",
    "            manual_mut_AA = mut_aa\n",
    "\n",
    "        # Try to extract position and get consensus base\n",
    "        match = re.search(r'(\\d+)', row['mutation'])\n",
    "        if match:\n",
    "            pos = int(match.group())\n",
    "            if 1 <= pos <= len(ref_seq):\n",
    "                con_base = ref_seq[pos - 1]\n",
    "            else:\n",
    "                con_base = 'N/A'\n",
    "        else:\n",
    "            con_base = 'N/A'\n",
    "\n",
    "        return pd.Series([orf, manual_mut_AA, mut_type, con_base])\n",
    "\n",
    "    df[['manual_prot', 'manual_mut_AA', 'mut_type', 'con_base']] = df.apply(apply_annotation, axis=1)\n",
    "    return df, n_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1b3f177",
   "metadata": {},
   "source": [
    "## Section 8: Annotate & Prepare Final Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac6725c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 12. Annotate\n",
    "annotated_df, n_df = annotate_dataframe(filtered_mutations_df, ref_seq, ORF_COORDS)\n",
    "\n",
    "# 13. Simplify & reorder\n",
    "if 'manual_mut_AA' in annotated_df: \n",
    "    annotated_df = annotated_df.rename(columns={'manual_mut_AA':'manual_mut'})\n",
    "if 'manual_prot' in annotated_df:\n",
    "    annotated_df = annotated_df.rename(columns={'manual_prot':'protein'})\n",
    "\n",
    "final_mutations_df = (\n",
    "    annotated_df\n",
    "    [['patient','timepoint','POS','mutation','manual_mut',\n",
    "      'protein','mut_type','final_freq','con_base']]\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "\n",
    "# 14. Adjust to absolute dates\n",
    "final_mutations_df['timepoint'] = final_mutations_df.apply(\n",
    "    lambda r: r['timepoint'] + days_to_add.get(r['patient'],0), axis=1\n",
    ")\n",
    "patients_tp_df['adjusted_timepoints'] = (\n",
    "    patients_tp_df.apply(\n",
    "        lambda r: [tp + days_to_add.get(r['patient'],0) for tp in r['timepoints']],\n",
    "        axis=1\n",
    "    )\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a9e606d",
   "metadata": {},
   "source": [
    "## Section 9: Export Timepoint Tables\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aa65bef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_timepoints_csvs(final_mutations_df, patients_tp_df, output_dir):\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    # If any POS values are missing, try extracting them from the 'mutation' column\n",
    "    if final_mutations_df['POS'].isnull().any():\n",
    "        def extract_pos(mut):\n",
    "            match = re.search(r'\\d+', str(mut))\n",
    "            return int(match.group()) if match else None\n",
    "\n",
    "        final_mutations_df['POS'] = final_mutations_df['POS'].fillna(\n",
    "            final_mutations_df['mutation'].apply(extract_pos)\n",
    "        )\n",
    "    # Iterate over each patient\n",
    "    for _, row in patients_tp_df.iterrows():\n",
    "        patient = row['patient']\n",
    "        timepoints = row['adjusted_timepoints']\n",
    "        # Filter mutations for that patient\n",
    "        patient_df = final_mutations_df[final_mutations_df['patient'] == patient]\n",
    "        # Get unique mutations for that patient (including POS!)\n",
    "        unique_mutations = patient_df[['POS','mutation', 'manual_mut', 'protein','mut_type']].drop_duplicates()\n",
    "        # Build a structure for the final dataframe\n",
    "        result_df = unique_mutations.copy()\n",
    "        # Initialize columns for each timepoint\n",
    "        for tp in timepoints:\n",
    "            result_df[str(tp)] = 0.0  # default to 0 if not found\n",
    "        # Fill in the frequencies with new logic\n",
    "        for idx, mut_row in result_df.iterrows():\n",
    "            mut = mut_row['mutation']\n",
    "            for tp in timepoints:\n",
    "                freq_row = patient_df[\n",
    "                    (patient_df['mutation'] == mut) &\n",
    "                    (patient_df['timepoint'] == tp)\n",
    "                ]\n",
    "                if not freq_row.empty:\n",
    "                    freq = freq_row['final_freq'].values[0]\n",
    "                    result_df.at[idx, str(tp)] = np.nan if freq == -1 else freq\n",
    "        # Sort by POS (ascending)\n",
    "        result_df = result_df.sort_values(by='POS', ascending=True)\n",
    "        # Save to CSV\n",
    "        output_path = os.path.join(output_dir, f\"{patient}_mutation_table.xlsx\")\n",
    "        result_df.to_excel(output_path, index=False)\n",
    "\n",
    "    print(f\"Mutation timepoint tables saved to {output_dir}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a796e7c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "build_timepoints_csvs(final_mutations_df, patients_tp_df, output_dir=freqs_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d98daab4",
   "metadata": {},
   "source": [
    "## Section 10: Plotting Functions & Main Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2479e82a",
   "metadata": {},
   "outputs": [],
   "source": [
    " #=== Fill missing POS ===\n",
    "if final_mutations_df['POS'].isnull().any():\n",
    "    def extract_pos(mut):\n",
    "        match = re.search(r'\\d+', str(mut))\n",
    "        return int(match.group()) if match else None\n",
    "    final_mutations_df['POS'] = final_mutations_df['POS'].fillna(\n",
    "        final_mutations_df['mutation'].apply(extract_pos)\n",
    "    )\n",
    "\n",
    "df = final_mutations_df.copy()\n",
    "df['final_after_manual'] = df['final_freq']\n",
    "\n",
    "# === Manual patient groups ===\n",
    "grouped_patients = {\n",
    "    \"21-37 Days\": [\"N4\", \"P4\", \"N8\", \"N7\"],\n",
    "    \"68-105 Days\": [\"N2\", \"N3\", \"P3\", \"P5\"],\n",
    "    \"241 Days\": [\"N1\"]\n",
    "}\n",
    "\n",
    "def remove_negative_frequencies(df):\n",
    "    return df[df['final_after_manual'] >= 0]\n",
    "\n",
    "def remove_zero_na_mutations(df):\n",
    "    return df.groupby('manual_mut').filter(\n",
    "        lambda x: (x['final_after_manual'] != 0).any() and x['final_after_manual'].notna().any()\n",
    "    )\n",
    "\n",
    "def clean_and_fill_missing_timepoints(patient_df, patient):\n",
    "    # Include all original timepoints from the patient (even from other mutations)\n",
    "    all_timepoints = sorted(patient_df['timepoint'].unique())\n",
    "    all_mutations = patient_df['manual_mut'].unique()\n",
    "\n",
    "    # Use this to preserve original data\n",
    "    filled_rows = []\n",
    "    final_rows = []\n",
    "\n",
    "    for mut in all_mutations:\n",
    "        mut_df = patient_df[patient_df['manual_mut'] == mut].copy()\n",
    "        existing_tps_all = set(mut_df['timepoint'])\n",
    "        valid_mut_df = mut_df[mut_df['final_after_manual'] != -1].copy()\n",
    "        valid_tps = set(valid_mut_df['timepoint'])\n",
    "\n",
    "        missing_tps = [tp for tp in all_timepoints if tp not in existing_tps_all]\n",
    "\n",
    "        # Add zeros for timepoints completely missing (and never had a -1)\n",
    "        for tp in missing_tps:\n",
    "            filled_rows.append({\n",
    "                'patient': patient,\n",
    "                'timepoint': tp,\n",
    "                'final_after_manual': 0,\n",
    "                'manual_mut': mut,\n",
    "                'mut_type': mut_df['mut_type'].iloc[0],\n",
    "                'POS': mut_df['POS'].iloc[0]\n",
    "            })\n",
    "\n",
    "        # Add valid original rows\n",
    "        final_rows.append(valid_mut_df)\n",
    "\n",
    "    if filled_rows:\n",
    "        final_rows.append(pd.DataFrame(filled_rows))\n",
    "\n",
    "    return pd.concat(final_rows, ignore_index=True)\n",
    "\n",
    "def save_legend_only_svg(color_dict, plot_folder, patient):\n",
    "    legend_fig = go.Figure()\n",
    "    for mut, color in color_dict.items():\n",
    "        legend_fig.add_trace(go.Scatter(\n",
    "            x=[None], y=[None],\n",
    "            mode='lines+markers',\n",
    "            name=mut,\n",
    "            showlegend=True,\n",
    "            line=dict(color=color, width=LINE_WIDTH),\n",
    "            marker=dict(color=color, size=MARKER_SIZE),\n",
    "            opacity=1\n",
    "        ))\n",
    "\n",
    "    legend_fig.update_layout(\n",
    "        showlegend=True,\n",
    "        legend=dict(\n",
    "            orientation='h',\n",
    "            x=0.5,\n",
    "            y=0.5,\n",
    "            xanchor='center',\n",
    "            yanchor='middle',\n",
    "            font=dict(size=FONT_SIZE_LEGEND, color=TEXT_COLOR)\n",
    "        ),\n",
    "        xaxis=dict(visible=False),\n",
    "        yaxis=dict(visible=False),\n",
    "        margin=dict(l=0, r=0, t=0, b=0),\n",
    "        height=200,\n",
    "        width=1000,\n",
    "        paper_bgcolor='white',\n",
    "        plot_bgcolor='white'\n",
    "    )\n",
    "\n",
    "    os.makedirs(plot_folder, exist_ok=True)\n",
    "    legend_path = os.path.join(plot_folder, f\"legend_{patient}.svg\")\n",
    "    legend_fig.write_image(legend_path)\n",
    "\n",
    "def plot_patient(patient_data, patient):\n",
    "    fig = go.Figure()\n",
    "\n",
    "    mutations = sorted(\n",
    "        patient_data['manual_mut'].unique(),\n",
    "        key=lambda x: patient_data[patient_data['manual_mut'] == x]['POS'].iloc[0]\n",
    "    )\n",
    "\n",
    "    high_freq_mutations = [\n",
    "        m for m in mutations\n",
    "        if patient_data[patient_data['manual_mut'] == m]['final_after_manual'].max() > 0.5\n",
    "    ]\n",
    "\n",
    "    color_dict = {\n",
    "        mut: PREDEFINED_COLORS[i % len(PREDEFINED_COLORS)]\n",
    "        for i, mut in enumerate(high_freq_mutations)\n",
    "    }\n",
    "\n",
    "    # Step 1: Precompute jitter per timepoint\n",
    "    jitter_lookup = {}  # {timepoint: {rounded_freq: list of mutations}}\n",
    "\n",
    "    for tp in sorted(patient_data['timepoint'].unique()):\n",
    "        tp_df = patient_data[\n",
    "            (patient_data['timepoint'] == tp) &\n",
    "            (patient_data['final_after_manual'] > 0.5)\n",
    "        ]\n",
    "        grouped = tp_df.groupby('manual_mut')\n",
    "        freq_bins = {}\n",
    "\n",
    "        for mut, group in grouped:\n",
    "            f = group['final_after_manual'].iloc[0]\n",
    "            rounded = round(f, 2)\n",
    "            if rounded not in freq_bins:\n",
    "                freq_bins[rounded] = []\n",
    "            freq_bins[rounded].append((mut, f))\n",
    "\n",
    "        jitter_lookup[tp] = {}\n",
    "        for rounded_val, entries in freq_bins.items():\n",
    "            n = len(entries)\n",
    "            jitter_range = 0.06 * rounded_val  # ±6% of freq\n",
    "            spacing = jitter_range / max(n - 1, 1) if n > 1 else 0\n",
    "            start = -jitter_range / 2\n",
    "            for i, (mut, f) in enumerate(sorted(entries)):\n",
    "                jitter_val = start + i * spacing\n",
    "                if tp not in jitter_lookup:\n",
    "                    jitter_lookup[tp] = {}\n",
    "                if mut not in jitter_lookup[tp]:\n",
    "                    jitter_lookup[tp][mut] = jitter_val\n",
    "\n",
    "    # Step 2: Plot mutation trends with jittered frequencies\n",
    "    for mut in mutations:\n",
    "        mut_df = patient_data[\n",
    "            (patient_data['manual_mut'] == mut) &\n",
    "            (patient_data['final_after_manual'] != -1)\n",
    "        ].sort_values('timepoint').copy()\n",
    "\n",
    "        if mut_df.empty:\n",
    "            continue\n",
    "\n",
    "        max_freq = mut_df['final_after_manual'].max()\n",
    "        mut_type = mut_df['mut_type'].iloc[0].lower()\n",
    "        line_style = 'dash' if mut_type in ['syn', 'mismatch'] else 'solid'\n",
    "        marker_symbol = 'triangle-up' if mut_type == 'indel' else 'circle'\n",
    "        show_in_legend = max_freq > 0.5\n",
    "        name_in_legend = mut if show_in_legend else ''\n",
    "\n",
    "        # Apply jitter if needed\n",
    "        jittered_freqs = []\n",
    "        for _, row in mut_df.iterrows():\n",
    "            f = row['final_after_manual']\n",
    "            tp = row['timepoint']\n",
    "            jitter_val = jitter_lookup.get(tp, {}).get(mut, 0)\n",
    "            jittered_freqs.append(f + jitter_val)\n",
    "\n",
    "        mut_df['plot_freq'] = jittered_freqs\n",
    "        color = color_dict.get(mut, LOW_FREQ_COLOR)\n",
    "\n",
    "        fig.add_trace(go.Scatter(\n",
    "            x=mut_df['timepoint'],\n",
    "            y=mut_df['plot_freq'],\n",
    "            mode='lines+markers',\n",
    "            name=name_in_legend,\n",
    "            showlegend=show_in_legend,\n",
    "            line=dict(color=color, dash=line_style, width=LINE_WIDTH),\n",
    "            marker=dict(color=color, size=MARKER_SIZE, symbol=marker_symbol),\n",
    "            opacity=OPACITY if not show_in_legend else 1\n",
    "        ))\n",
    "\n",
    "    tick_vals = sorted(patient_data['timepoint'].unique())\n",
    "    fig.update_layout(\n",
    "        title=f\"Patient {patient}\",\n",
    "        title_x=0.5,\n",
    "        title_y=0.99,\n",
    "        font=dict(size=FONT_SIZE_MAIN, color=TEXT_COLOR),\n",
    "        xaxis=dict(\n",
    "            title=\"Days\",\n",
    "            titlefont=dict(size=FONT_SIZE_AXIS_TITLE, color=TEXT_COLOR),\n",
    "            tickfont=dict(size=FONT_SIZE_TICK, color=TEXT_COLOR),\n",
    "            tickvals=tick_vals,\n",
    "            ticktext=[str(t) for t in tick_vals],\n",
    "            showgrid=True,\n",
    "            gridcolor=GRID_COLOR\n",
    "        ),\n",
    "        yaxis=dict(\n",
    "            title=\"Frequency\",\n",
    "            titlefont=dict(size=FONT_SIZE_AXIS_TITLE, color=TEXT_COLOR),\n",
    "            tickfont=dict(size=FONT_SIZE_TICK, color=TEXT_COLOR),\n",
    "            range=[-0.05, 1.1],  # show slightly outside 0-1\n",
    "            showgrid=True,\n",
    "            gridcolor=GRID_COLOR\n",
    "        ),\n",
    "        legend=dict(\n",
    "            orientation='h',\n",
    "            y=-0.2,\n",
    "            x=0.5,\n",
    "            xanchor='center',\n",
    "            font=dict(size=FONT_SIZE_LEGEND, color=TEXT_COLOR)\n",
    "        ),\n",
    "        margin=dict(l=40, r=40, t=120, b=100),\n",
    "        height=PLOT_HEIGHT,\n",
    "        width=PLOT_WIDTH,\n",
    "        paper_bgcolor='white',\n",
    "        plot_bgcolor='white'\n",
    "    )\n",
    "\n",
    "    os.makedirs(plot_folder, exist_ok=True)\n",
    "    png_path = os.path.join(plot_folder, f\"png_plot_{patient}.png\")\n",
    "    svg_path = os.path.join(plot_folder, f\"svg_plot_{patient}.svg\")\n",
    "    fig.write_image(png_path, scale=3)\n",
    "    fig.write_image(svg_path)\n",
    "\n",
    "    save_legend_only_svg(color_dict, plot_folder, patient)\n",
    "    return png_path, svg_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54a7de87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === execution ===\n",
    "all_patients = [(g, p) for g, plist in grouped_patients.items() for p in plist]\n",
    "for group_name, patient in tqdm(all_patients, desc=\"Generating plots and legends\"):\n",
    "    pdata = df[df['patient'] == patient].copy()\n",
    "    pdata = clean_and_fill_missing_timepoints(pdata, patient)\n",
    "    pdata = remove_negative_frequencies(pdata)\n",
    "    pdata = remove_zero_na_mutations(pdata)\n",
    "    if not pdata.empty:\n",
    "        plot_patient(pdata, patient)\n",
    "\n",
    "print(\"✅ All patient plots and legends saved (PNG + SVG).\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
